{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb85f50b-0919-4e4b-90e0-d864891d7ed0",
   "metadata": {},
   "source": [
    "# Fundamentals of Machine Learning (CSCI-UA.473)\n",
    "## Lab 6 : Convolutional Neural Networks (CNNs)\n",
    "\n",
    "We will test the following assumptions pertaining to CNNs \n",
    "\n",
    "* Compositionality obtained using many layers\n",
    "* Locality + stationarity of images assumed by the convolutional layers\n",
    "* Invariance of object class to translations assumed by the pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102034fd-9233-46c7-afba-056c1a584f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from plot_lib import plot_data, plot_model, set_default\n",
    "\n",
    "set_default()\n",
    "# Get our device in a variable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# function to count number of parameters\n",
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d821727-f461-46e1-8e82-87804cb93cb8",
   "metadata": {},
   "source": [
    "### Load the Dataset (MNIST)\n",
    "\n",
    "Load the MNIST handwritten digits dataset. We can use the PyTorch DataLoader utilities for this. This will download, shuffle, normalize data and arrange it in batches. Normalizing involves subtracting some coefficient (usually the mean) from each pixel values and dividing the resulting pixel values by another coefficient (usually the variance of the original pixel values). We also display some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb1ee81-1b80-4f6c-bdf0-a2d2a9a1d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size  = 28*28   # images are 28x28 pixels\n",
    "output_size = 10      # there are 10 classes\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e68388-1f74-43f9-b157-c0d7754488cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some images\n",
    "plt.figure(figsize=(16, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    plt.imshow(image.squeeze().numpy(), cmap='gray')\n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182deac-6d14-4ef4-bd6a-fa14396f6ff3",
   "metadata": {},
   "source": [
    "### Create the model classes\n",
    "For comparison purposes we will create two models classes: \n",
    "1. Multi-layer Perceptron\n",
    "2. Convolutional Neural Network\n",
    "\n",
    "Pay special attention to the order of the layer while creating CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd21334b-b88d-42e3-ab9b-c1c2c8d0ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC2Layer(nn.Module):\n",
    "    def __init__(self, input_size, n_hidden, output_size, activation='relu'):\n",
    "        super(FC2Layer, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        if activation =='relu':\n",
    "            self.activation = nn.ReLU()  \n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        else :\n",
    "            self.activation = nn.ReLU()\n",
    "            print(\"Activation function not implemented, using default ReLU\")\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, n_hidden), \n",
    "            self.activation,\n",
    "            nn.Linear(n_hidden, n_hidden), \n",
    "            self.activation,\n",
    "            nn.Linear(n_hidden, output_size), \n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)      \n",
    "        return self.network(x)\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, n_feature, output_size, activation='relu'):\n",
    "        super(CNN, self).__init__()\n",
    "        self.n_feature = n_feature\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(n_feature*4*4, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        if activation =='relu':\n",
    "            self.activation = nn.ReLU()  \n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        else :\n",
    "            print(\"Activation function not implemented, using default ReLU\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation(x) # Will it make a difference if we apply the non-linearity after the pooling layer?\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = x.view(-1, self.n_feature*4*4) # this is where are flattening the 2D feature maps into a single 1D vector so as to be used by the subsequent fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec5cff-defe-4373-a3a3-64c6d5b76c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, perm=torch.arange(0, 784).long(), verbose=False):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    losses = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # send data to device, where the \"device\" is either a GPU if it exists or a CPU\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # permute pixels\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass through the model\n",
    "        output = model(data)\n",
    "        # forward pass through the cross-entropy loss function\n",
    "        loss = F.nll_loss(output, target)\n",
    "        # backward pass through the cross-entropy loss function and the model\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            losses.append(loss.detach())\n",
    "            if verbose :\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return losses\n",
    "\n",
    "def test(model, perm=torch.arange(0, 784).long(), verbose=False):\n",
    "    model.eval()\n",
    "    accuracy_list = []\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # send data to device, where the \"device\" is either a GPU if it exists or a CPU\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # permute pixels\n",
    "            data = data.view(-1, 28*28)\n",
    "            data = data[:, perm]\n",
    "            data = data.view(-1, 1, 28, 28)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss                                                               \n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        accuracy_list.append(accuracy) \n",
    "        if verbose :\n",
    "            print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                test_loss, correct, len(test_loader.dataset),\n",
    "                accuracy))\n",
    "    return test_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4be7ad-453c-4f3b-b341-cfc2f6c96039",
   "metadata": {},
   "source": [
    "### Train a small MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba266637-1ab1-4d9e-8608-8a3cbde602c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 8 # number of hidden units\n",
    "model_fnn = FC2Layer(input_size, n_hidden, output_size)\n",
    "model_fnn = model_fnn.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model_fnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_fnn)))\n",
    "for epoch in range(0, 2):\n",
    "    train(epoch, model_fnn, optimizer, verbose=True)\n",
    "    test(model_fnn, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a08353-a62c-4989-9e0e-e78d2eb8a814",
   "metadata": {},
   "source": [
    "### Train a ConvNet with the same number of parameters\n",
    "Play around with the hyper-parameters to understand their relationship with model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd758d-488b-4e8b-bf1d-c626e2cbff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings \n",
    "n_features = 6 # number of feature maps\n",
    "\n",
    "model_cnn = CNN(input_size, n_features, output_size, activation='relu')\n",
    "model_cnn.to(device)\n",
    "optimizer = optim.SGD(model_cnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n",
    "for epoch in range(0, 2):\n",
    "    train(epoch, model_cnn, optimizer, verbose=True)\n",
    "    test(model_cnn, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc5138-99e8-4333-a0ad-0acba03b9d6e",
   "metadata": {},
   "source": [
    "### ConvNet performs better with the same number of parameters, thanks to its use of prior knowledge about images\n",
    "\n",
    "* Use of convolution: Locality and stationarity in images\n",
    "* Pooling: builds in some translation invariance\n",
    "\n",
    "### What happens if the assumptions are no longer true?\n",
    "Let us break the assumption of locality and permute the pixel within each image using an arbitrary permutation matrix. Also display the permuted images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9da844-31df-44ca-8602-f81e85c7d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = torch.randperm(784)\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i in range(10):\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    # permute pixels\n",
    "    image_perm = image.view(-1, 28*28).clone()\n",
    "    image_perm = image_perm[:, perm]\n",
    "    image_perm = image_perm.view(-1, 1, 28, 28)\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(image.squeeze().numpy(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(4, 5, i + 11)\n",
    "    plt.imshow(image_perm.squeeze().numpy(), cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0403f6-98d6-4d86-8641-bc106e380d7a",
   "metadata": {},
   "source": [
    "### CNNs with permuted pixels\n",
    "What do you think will happen to CNNs when given permuted pixels as inputs? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f727aa-6cb5-4a45-905b-d1b8ac1eaa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings \n",
    "n_features = 6 # number of feature maps\n",
    "\n",
    "\n",
    "model_cnn = CNN(input_size, n_features, output_size)\n",
    "model_cnn.to(device)\n",
    "optimizer = optim.SGD(model_cnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n",
    "for epoch in range(0, 3):\n",
    "    train(epoch, model_cnn, optimizer, perm)\n",
    "    test(model_cnn, perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79606ef7-8c84-41ba-8c4c-6a94d0b0c7db",
   "metadata": {},
   "source": [
    "### MLPs with permuted pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9b9b16-c1a7-4c6e-a216-d9d7bd6201f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 8    # number of hidden units\n",
    "\n",
    "model_fnn = FC2Layer(input_size, n_hidden, output_size)\n",
    "model_fnn.to(device)\n",
    "optimizer = optim.SGD(model_fnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_fnn)))\n",
    "\n",
    "for epoch in range(0, 2):\n",
    "    train(epoch, model_fnn, optimizer, perm, verbose=True)\n",
    "    test(model_fnn, perm, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acfddff-9e9d-4fa5-9157-1554cef89ee8",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "When we moved to Neural Networks we switched to ReLU as our activation function (or non-linearity). Recall that in logistic regression our non-linearty was the Sigmoid function. The sigmoid activation has a problem of vanishing gradients i.e. the gradients we get during backpropagation as often very close to 0. Think about what problem will this cause? In the next cell, we try both activations on our FC network and compare how the training proceeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde40a5a-1fbe-4125-a231-73ecc164f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 8 # number of hidden units\n",
    "model_fnn_1 = FC2Layer(input_size, n_hidden, output_size, activation='relu')\n",
    "model_fnn_1 = model_fnn_1.to(device)\n",
    "model_fnn_2 = FC2Layer(input_size, n_hidden, output_size, activation='sigmoid')\n",
    "model_fnn_2 = model_fnn_2.to(device)\n",
    "\n",
    "optimizer_1 = optim.SGD(model_fnn_1.parameters(), lr=0.01, momentum=0.5)\n",
    "optimizer_2 = optim.SGD(model_fnn_2.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_fnn_1)))\n",
    "train_losses_1 = []\n",
    "train_losses_2 = []\n",
    "for epoch in range(0, 5):\n",
    "    epoch_losses = train(epoch, model_fnn_1, optimizer_1)\n",
    "    train_losses_1.extend(epoch_losses)\n",
    "    epoch_losses = train(epoch, model_fnn_2, optimizer_2)\n",
    "    train_losses_2.extend(epoch_losses)\n",
    "plt.plot(train_losses_1, label='ReLU')\n",
    "plt.plot(train_losses_2, label='Sigmoid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b593f-9b87-4628-9098-40738979b235",
   "metadata": {},
   "source": [
    "Think about why does the Sigmoid function have this issue but not the ReLU?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa6d65-979c-4033-804f-63159a6180b4",
   "metadata": {},
   "source": [
    "### Using Dropout to prevent overfitting\n",
    "Dropout is a regularization technique which is now widely used to train deep neural networks. The idea is to randomly dropout some activations while training the models (Why would this help?). While the effect of using dropout is demonstrable for models on larger datasets (which takes longer to train!), we use a toy regression problem to demonstrate how dropout prevents overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba8769-1e44-40fb-883a-7d1b704feae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50 #number of data points\n",
    "noise = 0.3\n",
    "\n",
    "#generate the train data\n",
    "X_train = torch.unsqueeze(torch.linspace(-1, 1, N),1)\n",
    "Y_train = X_train + noise * torch.normal(torch.zeros(N,1), torch.ones(N,1))\n",
    "\n",
    "#generate the test data\n",
    "X_test = torch.unsqueeze(torch.linspace(-1,1,N),1)\n",
    "Y_test = X_test + noise * torch.normal(torch.zeros(N,1), torch.ones(N,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae29a3d-eccf-46ef-868c-e06787e4a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a neural network with out dropout\n",
    "N_h = 100 #hidden nodes\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(1, N_h),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(N_h, N_h),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(N_h, 1)\n",
    ")\n",
    "\n",
    "#create a network with dropout\n",
    "model_dropout = nn.Sequential(\n",
    "    nn.Linear(1, N_h),\n",
    "    nn.Dropout(0.5), #50 % probability \n",
    "    nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, N_h),\n",
    "    torch.nn.Dropout(0.2), #20% probability\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, 1),\n",
    ")\n",
    "\n",
    "plt.scatter(X_train.data.numpy(), Y_train.data.numpy(), c='purple', alpha=0.5, label='train')\n",
    "plt.scatter(X_test.data.numpy(), Y_test.data.numpy(), c='yellow', alpha=0.5, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1dd17-86ec-4760-b89a-9b7e4070a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of hidden layers\n",
    "N_h = 100\n",
    "\n",
    "# Define a FC model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, N_h),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, N_h),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, 1),\n",
    ")\n",
    "\n",
    "# Define a FC model with dropout -> simply add nn.Dropout(p) where p is the probability of randomly dropping out a node \n",
    "model_dropout = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, N_h),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, N_h),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27987d73-3e36-434e-abab-44e47e19d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "opt_dropout = torch.optim.Adam(model_dropout.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22397abb-ee75-4afb-ac17-da81537074d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 1000\n",
    "\n",
    "# Training blueprint - we are not using minibatches since our data is small enough to use it completely\n",
    "for epoch in range(max_epochs):\n",
    "    pred = model(X_train) \n",
    "    loss = loss_fn(pred, Y_train)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    pred_dropout = model_dropout(X_train)\n",
    "    loss_dropout = loss_fn(pred_dropout, Y_train)\n",
    "    opt_dropout.zero_grad()\n",
    "    loss_dropout.backward()\n",
    "    opt_dropout.step()\n",
    "    \n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        \n",
    "        model.eval()\n",
    "        model_dropout.eval()\n",
    "        \n",
    "        test_pred = model(X_test)\n",
    "        test_loss = loss_fn(test_pred, Y_test)\n",
    "        \n",
    "        test_pred_dropout = model_dropout(X_test)\n",
    "        test_loss_dropout = loss_fn(test_pred_dropout, Y_test)\n",
    "        \n",
    "        plt.scatter(X_train.data.numpy(), Y_train.data.numpy(), c='purple', alpha=0.5, label='train')\n",
    "        plt.scatter(X_test.data.numpy(), Y_test.data.numpy(), c='yellow', alpha=0.5, label='test')\n",
    "        plt.plot(X_test.data.numpy(), test_pred.data.numpy(), 'r-', lw=3, label='normal')\n",
    "        plt.plot(X_test.data.numpy(), test_pred_dropout.data.numpy(), 'b--', lw=3,  label='dropout')\n",
    "        \n",
    "        plt.title('Epoch %d, Loss = %0.4f, Loss with dropout = %0.4f' % (epoch, test_loss, test_loss_dropout))\n",
    "        \n",
    "        plt.legend()\n",
    "\n",
    "        model.train()\n",
    "        model_dropout.train()\n",
    "        \n",
    "        plt.pause(0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

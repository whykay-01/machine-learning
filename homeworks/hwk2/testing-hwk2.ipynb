{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e07279-41f5-4471-88f2-2a9ce6fdce0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported all!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "print(\"Imported all!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be775e22-1875-41ec-b963-8be2610d19a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before dropping:  1691334\n",
      "company                        5\n",
      "title                          0\n",
      "location                       0\n",
      "totalyearlycompensation        0\n",
      "basesalary                     0\n",
      "stockgrantvalue                0\n",
      "bonus                          0\n",
      "yearsofexperience              0\n",
      "yearsatcompany                 0\n",
      "gender                     19540\n",
      "Masters_Degree                 0\n",
      "Bachelors_Degree               0\n",
      "Doctorate_Degree               0\n",
      "Highschool                     0\n",
      "Some_College                   0\n",
      "Race_Asian                     0\n",
      "Race_White                     0\n",
      "Race_Two_Or_More               0\n",
      "Race_Black                     0\n",
      "Race_Hispanic                  0\n",
      "Race                       40215\n",
      "Education                  32272\n",
      "Age                            0\n",
      "Height                         0\n",
      "Zodiac                         0\n",
      "SAT                            0\n",
      "GPA                            0\n",
      "dtype: int64\n",
      "index: 0; spec num: 1; df['company']\n",
      "index: 1; spec num: 2; df['title']\n",
      "index: 2; spec num: 3; df['location']\n",
      "index: 3; spec num: 4; df['totalyearlycompensation']\n",
      "index: 4; spec num: 5; df['basesalary']\n",
      "index: 5; spec num: 6; df['stockgrantvalue']\n",
      "index: 6; spec num: 7; df['bonus']\n",
      "index: 7; spec num: 8; df['yearsofexperience']\n",
      "index: 8; spec num: 9; df['yearsatcompany']\n",
      "index: 9; spec num: 10; df['gender']\n",
      "index: 10; spec num: 11; df['Masters_Degree']\n",
      "index: 11; spec num: 12; df['Bachelors_Degree']\n",
      "index: 12; spec num: 13; df['Doctorate_Degree']\n",
      "index: 13; spec num: 14; df['Highschool']\n",
      "index: 14; spec num: 15; df['Some_College']\n",
      "index: 15; spec num: 16; df['Race_Asian']\n",
      "index: 16; spec num: 17; df['Race_White']\n",
      "index: 17; spec num: 18; df['Race_Two_Or_More']\n",
      "index: 18; spec num: 19; df['Race_Black']\n",
      "index: 19; spec num: 20; df['Race_Hispanic']\n",
      "index: 20; spec num: 21; df['Race']\n",
      "index: 21; spec num: 22; df['Education']\n",
      "index: 22; spec num: 23; df['Age']\n",
      "index: 23; spec num: 24; df['Height']\n",
      "index: 24; spec num: 25; df['Zodiac']\n",
      "index: 25; spec num: 26; df['SAT']\n",
      "index: 26; spec num: 27; df['GPA']\n"
     ]
    }
   ],
   "source": [
    "file_path = 'techSalaries2017.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Size before dropping: \", df.size)\n",
    "print(df.isnull().sum())\n",
    "for i, column_name in enumerate(df.columns.values.tolist()):\n",
    "    print(\"index:\", str(i) + \";\", \"spec num:\", str(i+1) + \";\", \"df['{}']\".format(column_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f8cb48-ceea-4de3-84c6-53bc7b6b809a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing 'company' column from the prediction data\n",
      "\n",
      "Removing 'title' column from the prediction data\n",
      "\n",
      "Removing 'location' column from the prediction data\n",
      "\n",
      "Removing 'basesalary' column from the dataset for total_yearly_compensation prediction\n",
      "\n",
      "Removing 'stockgrantvalue' column from the dataset for total_yearly_compensation prediction\n",
      "\n",
      "Removing 'bonus' column from the dataset for total_yearly_compensation prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalyearlycompensation</th>\n",
       "      <th>yearsofexperience</th>\n",
       "      <th>yearsatcompany</th>\n",
       "      <th>gender</th>\n",
       "      <th>Masters_Degree</th>\n",
       "      <th>Bachelors_Degree</th>\n",
       "      <th>Doctorate_Degree</th>\n",
       "      <th>Highschool</th>\n",
       "      <th>Some_College</th>\n",
       "      <th>Race_Asian</th>\n",
       "      <th>...</th>\n",
       "      <th>Race_Two_Or_More</th>\n",
       "      <th>Race_Black</th>\n",
       "      <th>Race_Hispanic</th>\n",
       "      <th>Race</th>\n",
       "      <th>Education</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Zodiac</th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>68.590</td>\n",
       "      <td>5</td>\n",
       "      <td>829</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>68.059</td>\n",
       "      <td>7</td>\n",
       "      <td>993</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>61.343</td>\n",
       "      <td>3</td>\n",
       "      <td>1200</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>66.495</td>\n",
       "      <td>3</td>\n",
       "      <td>1170</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>69.015</td>\n",
       "      <td>2</td>\n",
       "      <td>1115</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   totalyearlycompensation  yearsofexperience  yearsatcompany gender  \\\n",
       "0                   127000                1.5             1.5    NaN   \n",
       "1                   100000                5.0             3.0    NaN   \n",
       "2                   310000                8.0             0.0    NaN   \n",
       "3                   372000                7.0             5.0    NaN   \n",
       "4                   157000                5.0             3.0    NaN   \n",
       "\n",
       "   Masters_Degree  Bachelors_Degree  Doctorate_Degree  Highschool  \\\n",
       "0               0                 0                 0           0   \n",
       "1               0                 0                 0           0   \n",
       "2               0                 0                 0           0   \n",
       "3               0                 0                 0           0   \n",
       "4               0                 0                 0           0   \n",
       "\n",
       "   Some_College  Race_Asian  ...  Race_Two_Or_More  Race_Black  Race_Hispanic  \\\n",
       "0             0           0  ...                 0           0              0   \n",
       "1             0           0  ...                 0           0              0   \n",
       "2             0           0  ...                 0           0              0   \n",
       "3             0           0  ...                 0           0              0   \n",
       "4             0           0  ...                 0           0              0   \n",
       "\n",
       "   Race Education Age  Height  Zodiac   SAT   GPA  \n",
       "0   NaN       NaN  38  68.590       5   829  2.13  \n",
       "1   NaN       NaN  34  68.059       7   993  2.77  \n",
       "2   NaN       NaN  42  61.343       3  1200  3.26  \n",
       "3   NaN       NaN  28  66.495       3  1170  3.07  \n",
       "4   NaN       NaN  34  69.015       2  1115  2.91  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns we are not using for the predictions\n",
    "columns_to_drop = ['company', 'title', 'location']\n",
    "\n",
    "for column in columns_to_drop:\n",
    "    df = df.drop(column, axis=1)\n",
    "    print(\"\\nRemoving '{}' column from the prediction data\".format(column))\n",
    "\n",
    "\n",
    "# create a dataset for the total_yearly_compensation_prediction by removing `basesalary`, `stockgrantvalue`, `bonus` columns\n",
    "new_columns_to_drop = ['basesalary', 'stockgrantvalue', 'bonus']\n",
    "for column in new_columns_to_drop:\n",
    "    df = df.drop(column, axis=1)\n",
    "    print(\"\\nRemoving '{}' column from the dataset for total_yearly_compensation prediction\".format(column))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db8893fa-b286-4da1-8a32-dbe4b5b984bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 62642; Columns: 21\n"
     ]
    }
   ],
   "source": [
    "def return_shape(df):\n",
    "    return \"Rows: \" + str(df.shape[0]) + \"; Columns: \" + str(df.shape[1])\n",
    "\n",
    "print(return_shape(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30fe2e83-fbfc-475d-9b50-be322927868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 21591; Columns: 21\n"
     ]
    }
   ],
   "source": [
    "# let's drop all the columns that contain incomplete information about person's race or education\n",
    "new_df = df.dropna()\n",
    "print(return_shape(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734c6875-ab20-4ef1-8d11-3fa30416ad4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 21591; Columns: 19\n"
     ]
    }
   ],
   "source": [
    "# let's leave one dummy variable out for the education \n",
    "df = new_df.drop(\"Doctorate_Degree\", axis=1)\n",
    "\n",
    "# let's leave one dummy variable out for the race \n",
    "df = df.drop(\"Race_Two_Or_More\", axis=1)\n",
    "print(return_shape(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b8f60-e09b-4f75-9f91-9c54ce6612e5",
   "metadata": {},
   "source": [
    "### QUESTION 1: Using multiple linear regression: What is the best predictor of total annual compensation, how much variance is explained by this predictor vs. the full multiple regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a1dec7-c2dc-472c-8807-ada9890c9977",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/machine_learning_spring2024/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:565\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/machine_learning_spring2024/.venv/lib/python3.11/site-packages/pandas/core/construction.py:656\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    654\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[0;32m--> 656\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n",
      "File \u001b[0;32m~/machine_learning_spring2024/.venv/lib/python3.11/site-packages/pandas/core/construction.py:715\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m--> 715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    717\u001b[0m     )\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (21591, 1) instead",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m normalized_gpa_col \u001b[38;5;241m=\u001b[39m normalize_dataset(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPA\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     25\u001b[0m normalized_sat_col \u001b[38;5;241m=\u001b[39m normalize_dataset(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAT\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 27\u001b[0m normalized_gpa_and_sat \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_gpa_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_sat_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGPA_normalized\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSAT_normalized\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# We want to plot these values to identify what are the most useful predictors\u001b[39;00m\n\u001b[1;32m     30\u001b[0m predictors_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myearsofexperience\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myearsatcompany\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/machine_learning_spring2024/.venv/lib/python3.11/site-packages/pandas/core/frame.py:761\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    758\u001b[0m     data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (BlockManager, ArrayManager)):\n\u001b[0;32m--> 761\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m    767\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n",
      "File \u001b[0;32m~/machine_learning_spring2024/.venv/lib/python3.11/site-packages/pandas/core/generic.py:297\u001b[0m, in \u001b[0;36mNDFrame._init_mgr\u001b[0;34m(cls, mgr, axes, dtype, copy)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a, axe \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axe \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 297\u001b[0m         axe \u001b[38;5;241m=\u001b[39m \u001b[43mensure_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m         bm_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(a)\n\u001b[1;32m    299\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mreindex_axis(axe, axis\u001b[38;5;241m=\u001b[39mbm_axis)\n",
      "File \u001b[0;32m~/machine_learning_spring2024/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:7648\u001b[0m, in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   7646\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Index(index_like, copy\u001b[38;5;241m=\u001b[39mcopy, tupleize_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   7647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 7648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/machine_learning_spring2024/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:528\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_scalar_data_error(data)\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(data) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mmemoryview\u001b[39m):\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;66;03m# 2022-11-16 the memoryview check is only necessary on some CI\u001b[39;00m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;66;03m#  builds, not clear why\u001b[39;00m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_scalar_data_error(data)\n",
      "File \u001b[0;32m~/machine_learning_spring2024/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:570\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_scalar_data_error(data) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n\u001b[0;32m--> 570\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex data must be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    572\u001b[0m arr \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(arr)\n",
      "\u001b[0;31mValueError\u001b[0m: Index data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scatter_plot(ax, predictor, outcome, title):\n",
    "    ax.scatter(predictor, outcome, s=7, alpha=0.1, color=\"orange\")\n",
    "    ax.set_title(f\"{title} vs annual compensation\")\n",
    "    ax.set_xlabel(title)\n",
    "    ax.set_ylabel(\"total annual compensation\")\n",
    "\n",
    "\n",
    "def plot_scatter(data, header, outcome_variable):\n",
    "    indices = [(0, 0), (0, 1), (1, 0), (1, 1), (2, 0)]\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(12, 8))\n",
    "\n",
    "    for i, name in zip(indices, header):\n",
    "        scatter_plot(axs[i[0], i[1]], data[name], outcome_variable, name)\n",
    "\n",
    "def normalize_dataset(dataset):\n",
    "    mean = dataset.mean()\n",
    "    standard_deviation = dataset.std()\n",
    "\n",
    "    normalized_data = (dataset - mean) / standard_deviation\n",
    "    return pd.DataFrame(normalized_data)\n",
    "\n",
    "normalized_gpa_col = normalize_dataset(df['GPA'])\n",
    "normalized_sat_col = normalize_dataset(df['SAT'])\n",
    "\n",
    "normalized_gpa_and_sat = pd.DataFrame(normalized_gpa_col, normalized_sat_col, columns=['GPA_normalized', 'SAT_normalized'])\n",
    "\n",
    "# We want to plot these values to identify what are the most useful predictors\n",
    "predictors_list = ['GPA', 'SAT', 'Age', 'yearsofexperience', 'yearsatcompany']\n",
    "outcome_variable = df['totalyearlycompensation']\n",
    "my_predictors_df = pd.concat([df[predictors_list], normalized_gpa_and_sat], axis=1)\n",
    "\n",
    "my_predictors_df.head()\n",
    "\n",
    "plot_scatter(df[predictors_list], predictors_list, outcome_variable)\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3dfcd2-9bd5-4b32-b7e2-80c8c4a21578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
